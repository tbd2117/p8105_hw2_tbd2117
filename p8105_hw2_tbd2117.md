Homework 2
================
Thiago de Araujo - UNI tbd2117

``` r
library(tidyverse)
library(readxl)
library(haven)
```

### Problem 1

Reading and cleaning Mr. Trash Wheel Dataset

``` r
mr_trash_df = 
  read_excel("./data/MR_Trash_Wheel.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N408") %>% 
  janitor::clean_names() %>% 
  mutate(sports_balls = as.integer(sports_balls))
  
professor_trash_df = 
  read_excel("./data/MR_Trash_Wheel.xlsx", sheet = "Professor Trash Wheel", range = "A2:N80") %>% 
  janitor::clean_names() %>% 
  mutate(sports_balls = as.integer(sports_balls))

captain_trash_df = 
  read_excel("./data/MR_Trash_Wheel.xlsx", sheet = "Captain Trash Wheel", range = "A2:k20") %>% 
  janitor::clean_names()
```

**Read and clean precipitation data for 2017 and 2018. For each, omit
rows without precipitation data and add a variable year.**

``` r
precip_2018 = 
  read_excel("./data/MR_Trash_Wheel.xlsx", sheet = "2018 Precipitation", range = "A2:B14") %>% 
  janitor::clean_names() %>% 
  mutate(year = "2018") %>% 
  mutate(month = month.name)

precip_2017 = 
  read_excel("./data/MR_Trash_Wheel.xlsx", sheet = "2017 Precipitation", range = "A2:B14") %>% 
  janitor::clean_names() %>% 
  mutate(year = "2017") %>% 
  mutate(month = month.name)
```

**Next, combine precipitation datasets and convert month to a character
variable (the variable month.name is built into R and should be
useful).**

``` r
precipitation =
  bind_rows(precip_2017, precip_2018) %>%
  relocate(year)
```

**Write a paragraph about these data; you are encouraged to use inline
R. Be sure to note the number of observations in both resulting
datasets, and give examples of key variables.**

``` r
# median number of sports balls in a dumpster in 2017
sports_balls_2017 = bind_rows(mr_trash_df, professor_trash_df, captain_trash_df) %>% 
  select(sports_balls, year) %>% 
  drop_na() %>% 
  filter(year == "2017")

# total precipitation in 2018
sum(pull(precip_2018, total))
```

    ## [1] 70.33

The *mr\_trash\_df* dataset contains data on trash collected by
Mr. Trash Wheel. The dataset has 406 rows and 14 columns, and includes
data for dumpsters from 2014 to 2019.

The *professor\_trash\_df* contains data on trash collected by Professor
Trash Wheel. The dataset has 78 rows and 14 columns, and includes data
for dumpsters from 2017 to 2019.

The *captain\_trash\_df* contains data on trash collected by Captain
Trash Wheel. The dataset has 18 rows and 11 columns, and includes data
for dumpsters from 2018 to 2019.

**For available data, what was the total precipitation in 2018? What was
the median number of sports balls in a dumpster in 2017?**

The total precipitation in 2018 was 70.33in.

The median number of sports balls in a dumpster in 2017 was 7.

### Problem 2

**Read and clean the data; retain line, station, name, station latitude
/ longitude, routes served, entry, vending, entrance type, and ADA
compliance. Convert the entry variable from character (YES vs NO) to a
logical variable (the ifelse or recode function may be useful).**

``` r
transit = 
  read_csv("./data/NYC_Transit.csv") %>% 
  janitor::clean_names() %>% 
  select(line:route11, entry, vending, entrance_type, ada) %>% 
  mutate(entry = entry == "YES")
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

**Write a short paragraph about this dataset – explain briefly what
variables the dataset contains, describe your data cleaning steps so
far, and give the dimension (rows x columns) of the resulting dataset.**

The dataset *transit* contains information related to each entrance and
exit for each subway station in NYC. So far the variable names have been
cleaned and the variables of interest (line, station\_name,
station\_latitude, station\_longitude, route1, route2, route3, route4,
route5, route6, route7, route8, route9, route10, route11, entry,
vending, entrance\_type, ada) were selected. The dataset has 1868 rows
and 19 columns.

**Are these data tidy?**

These data could be tidy-er if repeated observations were excluded.

**How many distinct stations are there?**

``` r
transit_unique = distinct(transit, line, station_name, .keep_all=TRUE)
```

There are 465 distinct stations.

**How many stations are ADA compliant?**

84 stations are ADA compliant.

**What proportion of station entrances / exits without vending allow
entrance?**

4 of 9 stations entrances / exits without vending allow entrance.

Reformat data so that route number and route name are distinct
variables. How many distinct stations serve the A train? Of the stations
that serve the A train, how many are ADA compliant?

### Problem 3

This problem uses the FiveThirtyEight data; these data were gathered to
create the interactive graphic on this page. In particular, we’ll use
the data in pols-month.csv, unemployment.csv, and snp.csv. Our goal is
to merge these into a single data frame using year and month as keys
across datasets.

First, clean the data in pols-month.csv. Use separate() to break up the
variable mon into integer variables year, month, and day; replace month
number with month name; create a president variable taking values gop
and dem, and remove prez\_dem and prez\_gop; and remove the day
variable.

Second, clean the data in snp.csv using a similar process to the above.
For consistency across datasets, arrange according to year and month,
and organize so that year and month are the leading columns.

Third, tidy the unemployment data so that it can be merged with the
previous datasets. This process will involve switching from “wide” to
“long” format; ensuring that key variables have the same name; and
ensuring that key variables take the same values.

Join the datasets by merging snp into pols, and merging unemployment
into the result.

Write a short paragraph about these datasets. Explain briefly what each
dataset contained, and describe the resulting dataset (e.g. give the
dimension, range of years, and names of key variables).

Note: we could have used a date variable as a key instead of creating
year and month keys; doing so would help with some kinds of plotting,
and be a more accurate representation of the data. Date formats are
tricky, though. For more information check out the lubridate package in
the tidyverse.
