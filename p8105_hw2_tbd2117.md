Homework 2
================
Thiago de Araujo - UNI tbd2117

``` r
library(tidyverse)
library(readxl)
library(haven)
```

### Problem 1

Reading and cleaning Mr. Trash Wheel Dataset

``` r
mr_trash_df = 
  read_excel("./data/MR_Trash_Wheel.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N408") %>% 
  janitor::clean_names() %>% 
  mutate(sports_balls = as.integer(sports_balls))
  
professor_trash_df = 
  read_excel("./data/MR_Trash_Wheel.xlsx", sheet = "Professor Trash Wheel", range = "A2:N80") %>% 
  janitor::clean_names() %>% 
  mutate(sports_balls = as.integer(sports_balls))

captain_trash_df = 
  read_excel("./data/MR_Trash_Wheel.xlsx", sheet = "Captain Trash Wheel", range = "A2:k20") %>% 
  janitor::clean_names()
```

**Read and clean precipitation data for 2017 and 2018. For each, omit
rows without precipitation data and add a variable year.**

``` r
precip_2018 = 
  read_excel("./data/MR_Trash_Wheel.xlsx", sheet = "2018 Precipitation", range = "A2:B14") %>% 
  janitor::clean_names() %>% 
  mutate(year = "2018") %>% 
  mutate(month = month.name)

precip_2017 = 
  read_excel("./data/MR_Trash_Wheel.xlsx", sheet = "2017 Precipitation", range = "A2:B14") %>% 
  janitor::clean_names() %>% 
  mutate(year = "2017") %>% 
  mutate(month = month.name)
```

**Next, combine precipitation datasets and convert month to a character
variable (the variable month.name is built into R and should be
useful).**

``` r
precipitation =
  bind_rows(precip_2017, precip_2018) %>%
  relocate(year)
```

**Write a paragraph about these data; you are encouraged to use inline
R. Be sure to note the number of observations in both resulting
datasets, and give examples of key variables.**

``` r
# median number of sports balls in a dumpster in 2017
sports_balls_2017 = bind_rows(mr_trash_df, professor_trash_df, captain_trash_df) %>% 
  select(sports_balls, year) %>% 
  drop_na() %>% 
  filter(year == "2017")

# total precipitation in 2018
sum(pull(precip_2018, total))
```

    ## [1] 70.33

The *mr\_trash\_df* dataset contains data on trash collected by
Mr. Trash Wheel. The dataset has 406 rows and 14 columns, and includes
data for dumpsters from 2014 to 2019.

The *professor\_trash\_df* contains data on trash collected by Professor
Trash Wheel. The dataset has 78 rows and 14 columns, and includes data
for dumpsters from 2017 to 2019.

The *captain\_trash\_df* contains data on trash collected by Captain
Trash Wheel. The dataset has 18 rows and 11 columns, and includes data
for dumpsters from 2018 to 2019.

**For available data, what was the total precipitation in 2018? What was
the median number of sports balls in a dumpster in 2017?**

The total precipitation in 2018 was 70.33in.

The median number of sports balls in a dumpster in 2017 was 7.

### Problem 2

**Read and clean the data; retain line, station, name, station latitude
/ longitude, routes served, entry, vending, entrance type, and ADA
compliance. Convert the entry variable from character (YES vs NO) to a
logical variable (the ifelse or recode function may be useful).**

``` r
transit = 
  read_csv("./data/NYC_Transit.csv") %>% 
  janitor::clean_names() %>% 
  select(line:route11, entry, vending, entrance_type, ada) %>% 
  mutate(entry = entry == "YES")
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

**Write a short paragraph about this dataset – explain briefly what
variables the dataset contains, describe your data cleaning steps so
far, and give the dimension (rows x columns) of the resulting dataset.**

The dataset *transit* contains information related to each entrance and
exit for each subway station in NYC. So far the variable names have been
cleaned and the variables of interest (line, station\_name,
station\_latitude, station\_longitude, route1, route2, route3, route4,
route5, route6, route7, route8, route9, route10, route11, entry,
vending, entrance\_type, ada) were selected. The dataset has 1868 rows
and 19 columns.

**Are these data tidy?**

These data could be tidy-er if repeated observations were excluded.

**How many distinct stations are there?**

``` r
transit_unique = distinct(transit, line, station_name, .keep_all=TRUE)
# could also use count()
```

There are 465 distinct stations.

**How many stations are ADA compliant?**

84 stations are ADA compliant.

**What proportion of station entrances / exits without vending allow
entrance?**

4 of 9 stations entrances / exits without vending allow entrance.

**Reformat data so that route number and route name are distinct
variables.**

``` r
transit_reformat =
  transit_unique %>%
  mutate(route8 = as.character(route8), route9 = as.character(route9), route10 = as.character(route10),
      route11 = as.character(route11)) %>% 
  pivot_longer(
    route1:route11, 
    names_to = "route_number",
    names_prefix = "route",
    values_to = "route_name",
  )

str(transit_reformat)
```

    ## tibble [5,115 × 10] (S3: tbl_df/tbl/data.frame)
    ##  $ line             : chr [1:5115] "4 Avenue" "4 Avenue" "4 Avenue" "4 Avenue" ...
    ##  $ station_name     : chr [1:5115] "25th St" "25th St" "25th St" "25th St" ...
    ##  $ station_latitude : num [1:5115] 40.7 40.7 40.7 40.7 40.7 ...
    ##  $ station_longitude: num [1:5115] -74 -74 -74 -74 -74 ...
    ##  $ entry            : logi [1:5115] TRUE TRUE TRUE TRUE TRUE TRUE ...
    ##  $ vending          : chr [1:5115] "YES" "YES" "YES" "YES" ...
    ##  $ entrance_type    : chr [1:5115] "Stair" "Stair" "Stair" "Stair" ...
    ##  $ ada              : logi [1:5115] FALSE FALSE FALSE FALSE FALSE FALSE ...
    ##  $ route_number     : chr [1:5115] "1" "2" "3" "4" ...
    ##  $ route_name       : chr [1:5115] "R" NA NA NA ...

**How many distinct stations serve the A train? Of the stations that
serve the A train, how many are ADA compliant?**

60 distinct stations serve the A train, of which 17 are compliant.

### Problem 3

This problem uses the FiveThirtyEight data; these data were gathered to
create the interactive graphic on this page. In particular, we’ll use
the data in pols-month.csv, unemployment.csv, and snp.csv. Our goal is
to merge these into a single data frame using year and month as keys
across datasets.

**First, clean the data in pols-month.csv. Use separate() to break up
the variable mon into integer variables year, month, and day; replace
month number with month name; create a president variable taking values
gop and dem, and remove prez\_dem and prez\_gop; and remove the day
variable.**

``` r
pols = 
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month", "day"), sep = "-", convert = TRUE) %>%
  mutate(month = month.name[month]) %>% 
  mutate(president = if_else(prez_gop == 1, "gop", "dem")) %>%
  select(-prez_gop, -prez_dem, -day) %>% 
  mutate(year = as.numeric(year))
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

**Second, clean the data in snp.csv using a similar process to the
above. For consistency across datasets, arrange according to year and
month, and organize so that year and month are the leading columns.**

``` r
snp = 
  read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("month", "year", "day"), sep = "/", convert = TRUE) %>% 
  mutate(month = month.name[month]) %>% 
  select(year, month, close)
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

**Third, tidy the unemployment data so that it can be merged with the
previous datasets. This process will involve switching from “wide” to
“long” format; ensuring that key variables have the same name; and
ensuring that key variables take the same values.**

``` r
unemployment = 
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names() %>% 
   pivot_longer(
    jan:dec, 
    names_to = "month",
    values_to = "unemployment_pct"
  ) %>% 
  mutate(month = str_to_title(month)) %>%  
  mutate(month = match(month,month.abb)) %>% 
  mutate(month = month.name[month])
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

**Join the datasets by merging snp into pols, and merging unemployment
into the result.**

``` r
snp_pols =
  full_join(snp, pols)
```

    ## Joining, by = c("year", "month")

``` r
snp_pols_unemployment = 
  full_join(snp_pols, unemployment)
```

    ## Joining, by = c("year", "month")

**Write a short paragraph about these datasets. Explain briefly what
each dataset contained, and describe the resulting dataset (e.g. give
the dimension, range of years, and names of key variables).**

The dataset *snp\_pols\_unemployment* contains information related to
the number of national politicians who are democratic or republican as
well as the percentage of unemplyment at any given time as well as the
closing values of the S\&P stock index on the associated date.

The dataset has 1615 rows and 11 columns.
