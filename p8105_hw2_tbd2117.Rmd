---
title: "Homework 2"
author: "Thiago de Araujo - UNI tbd2117"
output: github_document
---

```{r message=FALSE}
library(tidyverse)
library(readxl)
library(haven)
```

### Problem 1

Reading and cleaning Mr. Trash Wheel Sheet

```{r}
mr_trash_df = 
  read_excel(
    "./data/MR_Trash_Wheel.xlsx", 
    sheet = "Mr. Trash Wheel", 
    range = "A2:N408") %>% 
  janitor::clean_names() %>%
  drop_na(dumpster) %>% 
  mutate(sports_balls = as.integer(sports_balls)
  )
```

**Read and clean precipitation data for 2017 and 2018. For each, omit rows without precipitation data and add a variable year.**

```{r}
precip_2018 = 
  read_excel(
    "./data/MR_Trash_Wheel.xlsx", 
    sheet = "2018 Precipitation", 
    range = "A2:B14") %>% 
  janitor::clean_names() %>% 
  mutate(year = "2018", month = month.name)

precip_2017 = 
  read_excel(
    "./data/MR_Trash_Wheel.xlsx", 
    sheet = "2017 Precipitation", 
    range = "A2:B14") %>% 
  janitor::clean_names() %>% 
  mutate(year = "2017", month = month.name)
```

**Next, combine precipitation datasets and convert month to a character variable (the variable month.name is built into R and should be useful).**

```{r}
precipitation =
  bind_rows(precip_2017, precip_2018) %>%
  relocate(year)
```

**Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in both resulting datasets, and give examples of key variables.** 
```{r}
# median number of sports balls in a dumpster in 2017
sports_balls_2017 = 
  select(mr_trash_df, sports_balls, year) %>%
  filter(year == "2017")

# total precipitation in 2018
sum(pull(precip_2018, total))
```

The _mr_trash_df_ dataset contains data on trash collected by Mr. Trash Wheel. The dataset has `r nrow(mr_trash_df)` rows and `r ncol(mr_trash_df)` columns, and includes data for dumpsters from `r min(pull(mr_trash_df, year), na.rm=TRUE)` to `r max(pull(mr_trash_df, year), na.rm=TRUE)`.

The _precipitation_ dataset contain monthly precipitation for the years 2017 and 2018. The dataset has `r nrow(precipitation)` rows and `r ncol(precipitation)` columns.

**For available data, what was the total precipitation in 2018? What was the median number of sports balls in a dumpster in 2017?**

The total precipitation in 2018 was `r sum(pull(precip_2018, total))`in.

The median number of sports balls in a dumpster in 2017 was `r median(pull(sports_balls_2017, sports_balls))`.

### Problem 2

**Read and clean the data; retain line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance. Convert the entry variable from character (YES vs NO) to a logical variable (the ifelse or recode function may be useful).**

```{r}
transit = 
  read_csv("./data/NYC_Transit.csv") %>% 
  janitor::clean_names() %>% 
  select(line:route11, entry, vending, entrance_type, ada) %>% 
  mutate(entry = entry == "YES")
```

**Write a short paragraph about this dataset – explain briefly what variables the dataset contains, describe your data cleaning steps so far, and give the dimension (rows x columns) of the resulting dataset.**

The dataset _transit_ contains information related to each entrance and exit for each subway station in NYC. So far the variable names have been cleaned and the variables of interest (`r colnames(transit)`) were selected. The dataset has `r nrow(transit)` rows and `r ncol(transit)` columns.

**Are these data tidy?**

These data could be tidy-er if repeated observations were excluded.

**How many distinct stations are there?**

```{r}
transit_unique = distinct(transit, line, station_name, .keep_all=TRUE)
# could also use count()
```

There are `r nrow(transit_unique)` distinct stations.

**How many stations are ADA compliant?**

`r sum(transit_unique$ada == TRUE)` stations are ADA compliant.

**What proportion of station entrances / exits without vending allow entrance?**

`r nrow(filter(transit_unique, vending =="NO", entry == "FALSE"))` of `r nrow(filter(transit_unique, vending == "NO"))` stations entrances / exits without vending allow entrance.

**Reformat data so that route number and route name are distinct variables.**

```{r}
transit_reformat =
  transit_unique %>%
  mutate(route8 = as.character(route8), route9 = as.character(route9), route10 = as.character(route10),
      route11 = as.character(route11)) %>% 
  pivot_longer(
    route1:route11, 
    names_to = "route_number",
    names_prefix = "route",
    values_to = "route_name",
  )
```

**How many distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?**

`r nrow(filter(transit_reformat, route_name =="A"))` distinct stations serve the A train, of which `r nrow(filter(transit_reformat, route_name =="A", ada == TRUE))` are compliant.

### Problem 3

This problem uses the FiveThirtyEight data; these data were gathered to create the interactive graphic on this page. In particular, we’ll use the data in pols-month.csv, unemployment.csv, and snp.csv. Our goal is to merge these into a single data frame using year and month as keys across datasets.

**First, clean the data in pols-month.csv. Use separate() to break up the variable mon into integer variables year, month, and day; replace month number with month name; create a president variable taking values gop and dem, and remove prez_dem and prez_gop; and remove the day variable.**

```{r}
pols = 
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month", "day"), sep = "-", convert = TRUE) %>%
  mutate(month = month.name[month]) %>% 
  mutate(president = if_else(prez_gop == 1, "gop", "dem")) %>%
  select(-prez_gop, -prez_dem, -day)
```

**Second, clean the data in snp.csv using a similar process to the above. For consistency across datasets, arrange according to year and month, and organize so that year and month are the leading columns.**

```{r}
snp = 
  read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("month", "day", "year"), sep = "/", convert = TRUE) %>% 
  mutate(month = month.name[month]) %>% 
  select(year, month, close)
```

**Third, tidy the unemployment data so that it can be merged with the previous datasets. This process will involve switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values.**

```{r}
unemployment = 
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec, 
    names_to = "month",
    values_to = "unemployment_pct"
  ) %>% 
  mutate(
    month = str_to_title(month), 
    month = match(month,month.abb),
    month = month.name[month]
  )
```

**Join the datasets by merging snp into pols, and merging unemployment into the result.**

```{r}
snp_pols =
  full_join(snp, pols)
snp_pols_unemployment = 
  full_join(snp_pols, unemployment)
```

**Write a short paragraph about these datasets. Explain briefly what each dataset contained, and describe the resulting dataset (e.g. give the dimension, range of years, and names of key variables).**

The dataset _snp_pols_unemployment_ contains information related to the number of national politicians who are democratic or republican as well as the percentage of unemplyment at any given time as well as the closing values of the S&P stock index on the associated date.

The dataset has `r nrow(snp_pols_unemployment)` rows and `r ncol(snp_pols_unemployment)` columns. It contains data from `r min(snp_pols_unemployment$year)` to `r max(snp_pols_unemployment$year)` for the following variables: `r colnames(snp_pols_unemployment)`.
